{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "import numpy as np\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check(row):\n",
    "    \"\"\"\n",
    "    Checks for human intervention in a plot\n",
    "    \"\"\"\n",
    "    if (row['DSTRBCD1'] == 80.0):\n",
    "        return True\n",
    "    if (row['DSTRBCD2'] == 80.0):\n",
    "        return True\n",
    "    if (row['DSTRBCD3'] == 80.0):\n",
    "        return True\n",
    "    if (row['TRTCD1'] == 10.0):\n",
    "        return True\n",
    "    if (row['TRTCD1'] == 30.0):\n",
    "        return True\n",
    "    if (row['TRTCD1'] == 50.0):\n",
    "        return True\n",
    "    if (row['TRTCD2'] == 10.0):\n",
    "        return True\n",
    "    if (row['TRTCD2'] == 30.0):\n",
    "        return True\n",
    "    if (row['TRTCD2'] == 50.0):\n",
    "        return True\n",
    "    if (row['TRTCD3'] == 10.0):\n",
    "        return True\n",
    "    if (row['TRTCD3'] == 30.0):\n",
    "        return True\n",
    "    if (row['TRTCD3'] == 50.0):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean(state):\n",
    "    \"\"\"\n",
    "    Cleans the data for usage in the analysis.\n",
    "    \"\"\"\n",
    "    in_file = 'data/'+state+'/'+state+'_1.csv'\n",
    "    out_file = 'data/'+state+'/'+state+'_2a.csv'\n",
    "    dstrb_web = \"http://apps.fs.fed.us/fiadb-downloads/CSV/\"+state+\"_COND.csv\"\n",
    "    data_points = pd.read_csv(in_file)\n",
    "    \n",
    "    #Remove entries before the year 1999\n",
    "    MIN_YR = 1999\n",
    "    data_points = data_points[data_points['py'] % 10000 >= MIN_YR]\n",
    "    #Remove entries with few trees\n",
    "    MIN_TREES = 5\n",
    "    data_points = data_points[data_points['samples'] - data_points['na'] >= MIN_TREES]\n",
    "    #Remove entries with too many invalid trees\n",
    "    NA_THRESHOLD = 5\n",
    "    data_points = data_points[data_points['na'] < NA_THRESHOLD]\n",
    "    #Keep only most importaqnt species\n",
    "    MIN_IV = 0.7\n",
    "    keep_cols = [col for col in list(data_points) if not col.startswith('iv')]\n",
    "    col_iv = [col for col in list(data_points) if col.startswith('iv')]\n",
    "    sorted_iv = data_points[col_iv].apply(sum, axis=0).sort_values(ascending=False)\n",
    "    cutoff = bisect.bisect_left(np.cumsum(sorted_iv), len(data_points.index) * MIN_IV) +1\n",
    "    #Add 1 to the cutoff so the total IV is guaranteed to be over MIN_IV\n",
    "    for i in np.arange(cutoff):\n",
    "        keep_cols.append(sorted_iv.index[i])  \n",
    "    data_points = data_points.loc[:, keep_cols]\n",
    "    #Drop samples and na.  They're not necessary anymore\n",
    "    data_points = data_points.drop(['samples','na'], axis = 1)\n",
    "    data_points.to_csv(out_file, index=False)\n",
    "    out_file = 'data/'+state+'/'+state+'_2b.csv'\n",
    "    \n",
    "    \n",
    "    DSTRB_COLS = [\n",
    "        'PLOT', 'INVYR', 'DSTRBCD1', 'DSTRBCD2', 'DSTRBCD3',\n",
    "        'TRTCD1', 'TRTCD2', 'TRTCD3'\n",
    "    ]\n",
    "    disturbance = pd.read_csv(dstrb_web, usecols=DSTRB_COLS)\n",
    "    \n",
    "    #Mark plots where human intervention happened\n",
    "    data_points.set_index('py', inplace=True)\n",
    "    data_points.loc[:,'human'] = 0\n",
    "    for i, row in disturbance.iterrows():\n",
    "        py = int(row['INVYR'] + row['PLOT'] * 10000)\n",
    "        if py in data_points.index:\n",
    "            if check(row):\n",
    "                data_points.loc[int(row['INVYR'] + row['PLOT'] * 10000), 'human'] = 1\n",
    "    data_points.reset_index(inplace=True)\n",
    "    data_points.loc[:, 'py'] = data_points.loc[:, 'py'].apply(int)\n",
    "    #Re-number the plots so that human interventions are not applied\n",
    "    cur_np = 1\n",
    "    prev_id = data_points.loc[0, 'py'] // 10000\n",
    "    for i, row in data_points.iterrows():\n",
    "        if (prev_id != row['py'] // 10000) or (row['human'] == 1):\n",
    "            cur_np += 1\n",
    "        prev_id = row['py'] // 10000\n",
    "        data_points.loc[i, 'py'] = int(cur_np * 10000 + row['py'] % 10000)\n",
    "    data_points = data_points.drop(['human'], axis = 1)\n",
    "    data_points.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for STATE in ['ME']:\n",
    "    clean(STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'AL','AZ','AR','CA','CO','CT','DE','DC','FL','GA','ID','IL','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WI','WY'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
