{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "with open('data/centroids.json', 'r') as infile:\n",
    "    centroids = json.load(infile)\n",
    "with open('data/labels.json', 'r') as infile:\n",
    "    labels = json.load(infile)\n",
    "data_csv = 'data/normalized_points.csv'\n",
    "data_points = pd.read_csv(data_csv,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Reminder: attributes start their numbering with 2, not 0\n",
    "#This snippet creates the dictionary based on the data_points:\n",
    "\"\"\"\n",
    "plots_dd: {\n",
    "        <plot_num>: [(year,plot_state),...]\n",
    "    }\n",
    "\"\"\"\n",
    "plots_dd = defaultdict(lambda:[])\n",
    "for i, row in data_points.iterrows():\n",
    "    plots_dd[row[0]].append((row[1],labels[i]))\n",
    "for i in plots_dd:\n",
    "    plots_dd[i].sort()\n",
    "data_points.set_index([0,1],drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the Markov State Matrix\n",
    "markov_df = pd.DataFrame(0.0, index=np.arange(len(centroids)), columns=np.arange(len(centroids))) #The dimensions of the matrix are the number of clusters\n",
    "for i in plots_dd:\n",
    "    prev_y = None\n",
    "    prev_s = None\n",
    "    for year, state in plots_dd[i]:\n",
    "        if prev_y is not None:\n",
    "            markov_df.iloc[prev_s][state] += 1 - 0.5**(1/(year-prev_y))                           #For each change of state, record it in the matrix\n",
    "        prev_y = year\n",
    "        prev_s = state\n",
    "r_sum = markov_df.sum(axis=1)\n",
    "markov_df = markov_df.truediv(r_sum,axis=0)                                                       #Weight each row so all rows sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fitness(msm,plots_dd,centroids,data):\n",
    "    \"\"\"\n",
    "    msm: DataFrame representing the Markov State Matrix\n",
    "    plots_dd: {\n",
    "        <plot_num>: [(year,plot_state),...]\n",
    "    }\n",
    "    centroids stores the coordinates of the cluster centers\n",
    "    data stores the coordinates of each pair (plot, year)\n",
    "    \"\"\"\n",
    "    score = 0.0\n",
    "    num_trans = 0\n",
    "    for plot in plots_dd:\n",
    "        prev_y = None\n",
    "        prev_s = None\n",
    "        for year, state in plots_dd[plot]:\n",
    "            if prev_y is not None:                                       #The new state can only be predicted if there is data for a previous one\n",
    "                num_trans += 1\n",
    "                dist = []\n",
    "                cur_v = data.loc[plot].loc[year]                         #Retrieve the data of the plot that is being analyzed right now\n",
    "                for c in centroids:\n",
    "                    dist.append(np.linalg.norm(cur_v-c))                 #Calculate the distance between each centroid and the actual value\n",
    "                msm_time = np.linalg.matrix_power(msm,int(year-prev_y))  #Raise the matrix to the nth power\n",
    "                r_prob = msm_time[prev_s]                                #Extract the row that corresponds to the current state\n",
    "                score += np.sum(r_prob*dist)                             #Multiply each distance by its corresponding probability\n",
    "            prev_y = year\n",
    "            prev_s = state\n",
    "    return num_trans/score                                               #The greater this value, the better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function needs optimization. (14 seconds in Athena computer)\n",
    "fitness(markov_df,plots_dd,centroids,data_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
