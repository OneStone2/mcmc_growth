{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "data_csv = 'data/points.csv'\n",
    "data_points = pd.read_csv(data_csv,header=None,index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply PCA\n",
    "pca = PCA(n_components='mle')\n",
    "data_trans = pca.fit_transform(data_points)\n",
    "data_points.reset_index(level=1, inplace=True)\n",
    "data_points.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the clusters based on the PCA axes\n",
    "n_clusters = 10\n",
    "clusters=KMeans(n_clusters=n_clusters).fit(data_trans)\n",
    "centroids = clusters.cluster_centers_\n",
    "labels = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plots_dd: {\n",
    "        <plot_num>: [(year,plot_state),...]\n",
    "    }\n",
    "\"\"\"\n",
    "plots_dd = defaultdict(lambda:[])\n",
    "for i, row in data_points.iterrows():\n",
    "    plots_dd[row[0]].append((row[1],labels[i]))\n",
    "for i in plots_dd:\n",
    "    plots_dd[i].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split all the plots randomly into 11 equally-sized groups\n",
    "#The first 10 are used to create the model with cross-validation\n",
    "#Once we have a Markov State transition matrix, the 11th group is used for validation\n",
    "n_buckets = 10\n",
    "random.seed()\n",
    "group = []\n",
    "while len(group)<n_buckets+1: group.append([])\n",
    "bucket = np.arange(n_buckets+1).tolist()\n",
    "for plot in plots_dd:\n",
    "    rand = random.randint(0,len(bucket)-1)\n",
    "    group[bucket[rand]].append(plot)\n",
    "    bucket.pop(rand)\n",
    "    if len(bucket)==0: bucket = np.arange(n_buckets+1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best = pd.DataFrame(1/n_clusters, index = np.arange(n_clusters), columns = np.arange(n_clusters))\n",
    "best_p = 0.0\n",
    "for i in np.arange(n_buckets):\n",
    "    cur = defaultdict(lambda: pd.DataFrame(0.0, index = np.arange(n_clusters), columns = np.arange(n_clusters)))\n",
    "    state_weight = defaultdict(lambda: [0]*n_clusters)\n",
    "    diff_weight = defaultdict(int)\n",
    "    sum_diff_weight = 0.0\n",
    "    cur_obs = defaultdict(lambda: pd.DataFrame(0, index = np.arange(n_clusters), columns = np.arange(n_clusters)))\n",
    "    for j in np.arange(n_buckets):\n",
    "        for plot in (plots_dd[x] for x in group[j]):\n",
    "            prev_y = None\n",
    "            prev_s = None\n",
    "            for year, state in plot:\n",
    "                if prev_y != None:\n",
    "                    diff_y = int(float(year - prev_y))\n",
    "                    if i == j:                       \n",
    "                        cur_obs[diff_y].loc[prev_s,state] += 1\n",
    "                    else:\n",
    "                        cur[diff_y].loc[prev_s,state] += 1\n",
    "                        state_weight[diff_y][prev_s] += 1\n",
    "                        diff_weight[diff_y] += 1\n",
    "                        sum_diff_weight += 1\n",
    "                prev_y = year\n",
    "                prev_s = state\n",
    "    final = pd.DataFrame(0.0, index = np.arange(n_clusters), columns = np.arange(n_clusters))\n",
    "    for diff_y in diff_weight:\n",
    "        diff_weight[diff_y] = diff_weight[diff_y] / sum_diff_weight\n",
    "    for diff_y in cur:\n",
    "        state_weight[diff_y] = [x if x != 0 else 1 for x in state_weight[diff_y]]\n",
    "        cur[diff_y] = cur[diff_y].divide(state_weight[diff_y], axis = 0)\n",
    "        cur[diff_y] = pd.DataFrame(linalg.fractional_matrix_power(cur[diff_y].values, 1.0/diff_y))\n",
    "        #Drop the imaginary part. It is small, so it doesn't affect performance\n",
    "        cur[diff_y] = cur[diff_y].apply(lambda x: np.real(x))       \n",
    "        #Some values will be negative. Set those to 0\n",
    "        cur[diff_y][cur[diff_y] < 0] = 0\n",
    "        #Rescale the rows so they add up to 1\n",
    "        cur[diff_y] = cur[diff_y].divide(cur[diff_y].sum(axis = 0), axis = 1)\n",
    "        cur[diff_y].fillna(0, inplace = True)\n",
    "        final = final + cur[diff_y].multiply(diff_weight[diff_y])    \n",
    "    #Test how good the model is using chi-squared test\n",
    "    exp_arr = []\n",
    "    obs_arr = []\n",
    "    for diff_y in state_weight:\n",
    "        cur_exp = pd.DataFrame(np.linalg.matrix_power(final, diff_y))\n",
    "        cur_exp = cur_exp.multiply(cur_obs[diff_y].sum(axis = 0), axis = 1)\n",
    "        #Drop all cells with an expected value of less than 5\n",
    "        #Chi-square relies on having 5 or more data points per cell\n",
    "        #Performance of cells with low probabilities do not affect much the model\n",
    "        for k, row in cur_exp.iterrows():\n",
    "            indices = [l for l,v in enumerate(row) if v >= 5]\n",
    "            for l in indices:\n",
    "                exp_arr.append(cur_exp.iloc[k,l])\n",
    "                obs_arr.append(cur_obs[diff_y].iloc[k,l])\n",
    "    p_value = stats.chisquare(obs_arr, exp_arr)[1]\n",
    "    if p_value > best_p:\n",
    "        best_p = p_value\n",
    "        best = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Then, test the best matrix against the 11th group\n",
    "cur_obs = defaultdict(lambda: pd.DataFrame(0, index = np.arange(n_clusters), columns = np.arange(n_clusters)))\n",
    "for plot in (plots_dd[x] for x in group[n_buckets]):\n",
    "    prev_y = None\n",
    "    prev_s = None\n",
    "    for year, state in plot:\n",
    "        if prev_y != None:\n",
    "            diff_y = int(float(year - prev_y))                    \n",
    "            cur_obs[diff_y].loc[prev_s,state] += 1\n",
    "        prev_y = year\n",
    "        prev_s = state\n",
    "exp_arr = []\n",
    "obs_arr = []\n",
    "for diff_y in state_weight:\n",
    "    cur_exp = pd.DataFrame(np.linalg.matrix_power(best, diff_y))\n",
    "    cur_exp = cur_exp.multiply(cur_obs[diff_y].sum(axis = 0), axis = 1)\n",
    "    #Drop all cells with an expected value of less than 5\n",
    "    #Chi-square relies on having 5 or more data points per cell\n",
    "    #Performance of cells with low probabilities do not affect much the model\n",
    "    for k, row in cur_exp.iterrows():\n",
    "        indices = [l for l,v in enumerate(row) if v >= 5]\n",
    "        for l in indices:\n",
    "            exp_arr.append(cur_exp.iloc[k,l])\n",
    "            obs_arr.append(cur_obs[diff_y].iloc[k,l])\n",
    "print stats.chisquare(obs_arr, exp_arr)[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
