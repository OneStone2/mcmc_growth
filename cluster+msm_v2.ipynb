{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "data_csv = 'data/points.csv'\n",
    "data_points = pd.read_csv(data_csv,header=None,index_col=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply PCA\n",
    "pca = PCA(n_components='mle')\n",
    "data_trans = pca.fit_transform(data_points)\n",
    "data_points.reset_index(level=1, inplace=True)\n",
    "data_points.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the clusters based on the PCA axes\n",
    "n_clusters = 10\n",
    "clusters=KMeans(n_clusters=n_clusters).fit(data_trans)\n",
    "centroids = clusters.cluster_centers_\n",
    "labels = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plots_dd: {\n",
    "        <plot_num>: [(year,plot_state),...]\n",
    "    }\n",
    "\"\"\"\n",
    "plots_dd = defaultdict(lambda:[])\n",
    "for i, row in data_points.iterrows():\n",
    "    plots_dd[row[0]].append((row[1],labels[i]))\n",
    "for i in plots_dd:\n",
    "    plots_dd[i].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split all the plots randomly into 11 equally-sized groups\n",
    "#The first 10 are used to create the model with cross-validation\n",
    "#Once we have a Markov State transition matrix, the 11th group is used for validation\n",
    "n_buckets = 10\n",
    "random.seed()\n",
    "group = []\n",
    "while len(group)<n_buckets+1: group.append([])\n",
    "bucket = np.arange(n_buckets+1).tolist()\n",
    "for plot in plots_dd:\n",
    "    rand = random.randint(0,len(bucket)-1)\n",
    "    group[bucket[rand]].append(plot)\n",
    "    bucket.pop(rand)\n",
    "    if len(bucket)==0: bucket = np.arange(n_buckets+1).tolist()\n",
    "#The resulting data is split into 11 groups\n",
    "#It's important to remember what a group is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Since this snippet is essentially impossible to understand,\n",
    "I explain what it attempts to do in words.\n",
    "Repeat this process 10 times:\n",
    "Construct a Markov State transition matrix in the standard way.\n",
    "We only use 9 groups to construct it.\n",
    "Then, evaluate its performance testing it against the group we didn't use.\n",
    "The performance is the p-value when running the chi-squared test.\n",
    "\n",
    "Once all 10 matrices are constructed, take the best of them.\n",
    "\"\"\"\n",
    "\n",
    "#Repeat the process of creating the Markov State transition matrix 10 times\n",
    "#Afterwards, choose the better one (highest p-value)\n",
    "#Matrix i is created from data in all groups except i and cross-validated with group i\n",
    "markov_df = []\n",
    "#The p-value for each matrix is stored\n",
    "p_values = [0.0]*n_buckets\n",
    "#Create the list of 10 Markov State Matrices\n",
    "#The dimensions of the matrix are the number of clusters\n",
    "while len(markov_df)<n_buckets+1: \n",
    "    markov_df.append(pd.DataFrame(0.0, index=np.arange(n_clusters), columns=np.arange(n_clusters)))\n",
    "for i in np.arange(n_buckets):\n",
    "    #Create a separate matrix containing only data from i\n",
    "    #We assume all transitions are for 5 years for this matrix only\n",
    "    observed = pd.DataFrame(0.0, index=np.arange(n_clusters), columns=np.arange(n_clusters))\n",
    "    count = [0]*n_buckets\n",
    "    for j in np.arange(n_buckets):\n",
    "        for plot in group[j]:\n",
    "            prev_y = None\n",
    "            prev_s = None\n",
    "            for year, state in plots_dd[plot]:\n",
    "                if prev_y is not None:\n",
    "                    if j==i:\n",
    "                        #Record change of state in the observed matrix\n",
    "                        observed[prev_s][state] = observed[prev_s][state] + 1\n",
    "                        count[prev_s] += 1\n",
    "                    else:\n",
    "                        #Record each change of state into the matrix\n",
    "                        markov_df[i].iloc[prev_s][state] += 1 - 0.5**(1/(year-prev_y))                           \n",
    "                prev_y = year\n",
    "                prev_s = state\n",
    "    r_sum = markov_df[i].sum(axis=1)\n",
    "    for state, row in markov_df[i].iterrows():\n",
    "    #Some states only appear in the last measurement of some plots\n",
    "    #As such, the row for this state only contains 0\n",
    "    #To avoid buggy behavior, set them as absorbing states and set the probability to 1\n",
    "        if r_sum[state]==0:\n",
    "            r_sum[state]=1\n",
    "            markov_df[i].iloc[state,state]=1\n",
    "    #Weight each row so all rows sum to 1\n",
    "    markov_df[i] = markov_df[i].truediv(r_sum,axis=0)\n",
    "    #Calculate the expected value for the constructed Markov State transition matrix\n",
    "    #Raise to the 5th power since we assumed all transitions are for 5 years\n",
    "    expected = markov_df[i].values\n",
    "    expected = np.matrix(expected)\n",
    "    expected = expected**5\n",
    "    for i, row in enumerate(expected):\n",
    "        expected[i] =  np.multiply(row,count[i])\n",
    "    #When calculating chi-square test, all expected values should be at least 5\n",
    "    #Discard cells with expected values less than 5\n",
    "    #Put remaining cells into lists to avoid messy tables\n",
    "    observed_l = []\n",
    "    expected_l = []\n",
    "    for i in np.arange(n_clusters):\n",
    "        for j in np.arange(n_clusters):\n",
    "            if (expected.item((i,j)) >= 5):\n",
    "                observed_l.append(observed[i][j])\n",
    "                expected_l.append(expected.item((i,j)))\n",
    "    p_values[i]=stats.chisquare(observed_l,expected_l)[1]\n",
    "max_p = max(p_values)\n",
    "max_index = p_values.index(max_p)\n",
    "markov_df = markov_df[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Evaluate performance of the matrix with the 11th group\n",
    "#For sake of simplicity, we assume all the transitions are done within 5 years\n",
    "#Only 10% of them are done within 4 or 6 years and only 1% within 7 or more\n",
    "for plot in group[n_buckets]:\n",
    "    prev_y = None\n",
    "    prev_s = None\n",
    "    for year, state in plots_dd[plot]:\n",
    "        if prev_y is not None:\n",
    "            if j==i:\n",
    "                #Record change of state in the observed matrix\n",
    "                observed[prev_s][state] = observed[prev_s][state] + 1\n",
    "                count[prev_s] += 1\n",
    "        prev_y = year\n",
    "        prev_s = state\n",
    "expected = markov_df.values\n",
    "expected = np.matrix(expected)\n",
    "expected = expected**5\n",
    "for i, row in enumerate(expected):\n",
    "    expected[i] =  np.multiply(row,count[i])\n",
    "    #When calculating chi-square test, all expected values should be at least 5\n",
    "    #Discard cells with expected values less than 5\n",
    "    #Put remaining cells into lists to avoid messy tables\n",
    "    observed_l = []\n",
    "    expected_l = []\n",
    "    for i in np.arange(n_clusters):\n",
    "        for j in np.arange(n_clusters):\n",
    "            if (expected.item((i,j)) >= 5):\n",
    "                observed_l.append(observed[i][j])\n",
    "                expected_l.append(expected.item((i,j)))\n",
    "#Output is a number between 0 and 1. 1 is best, 0 is worst\n",
    "print(stats.chisquare(observed_l,expected_l)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
